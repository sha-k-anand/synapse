df = spark.read.load('abfss://tpch-sf1000-consolidated@tpchdata.dfs.core.windows.net/SUPPLIER/', format='parquet')
display(df.limit(10))


df.write.format("delta").partitionBy("S_NATIONKEY").save("abfss://zztest@tpchdata.dfs.core.windows.net/Delta_SUPPLIER_part2/")

%%sql
CREATE TABLE zzDelta_SUPPLIER_part1 
(
S_SUPPKEY bigint, 
S_NAME string,
S_ADDRESS string,
S_NATIONKEY bigint,
S_PHONE string,
S_ACCTBAL decimal(9,2) ,
S_COMMENT string
)
USING DELTA  PARTITIONED BY (S_NATIONKEY) OPTIONS (path 'abfss://zztest@tpchdata.dfs.core.windows.net/Delta_SUPPLIER_part2/')


%%sql
select count(*) from zzDelta_SUPPLIER_part1

%%sql
UPDATE zzDelta_SUPPLIER_part1 SET S_COMMENT = 'test1111' WHERE S_NATIONKEY = 23

%%sql
select * from zzDelta_SUPPLIER_part1  WHERE S_NATIONKEY = 23
